{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2eca799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "  tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d0fe536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SBAUser\\AppData\\Local\\Temp\\ipykernel_17540\\856612470.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gpu 연결 체크\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False,\n",
    "    min_cuda_compute_capability=None\n",
    ")\n",
    "# True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "081003d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20108 images belonging to 4 classes.\n",
      "배치 데이터 크기: (16, 150, 150, 3)\n",
      "배치 레이블 크기: (16,)\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 360,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip = True,\n",
    "                                   fill_mode = 'nearest')\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                  'resample',\n",
    "                  target_size = (150, 150),\n",
    "                  batch_size = 16,\n",
    "                  class_mode = 'sparse')\n",
    "\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    # 데이터 하나만 체크해보자\n",
    "    print('배치 데이터 크기:', data_batch.shape)\n",
    "    print('배치 레이블 크기:', labels_batch.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df1145a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"converea\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " img (InputLayer)            [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 75, 75, 16)        448       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 75, 75, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 25, 25, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 25, 25, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10816)             0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 10816)            43264     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10816)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               5538304   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,712,004\n",
      "Trainable params: 5,690,372\n",
      "Non-trainable params: 21,632\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(150, 150, 3), name=\"img\")\n",
    "x = layers.Conv2D(16, 3, 2, padding = 'same', activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(32, 3, 1, padding ='same', activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(64, 3, 1, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2D(64, 3, 2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(512, activation=\"relu\")(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(4)(x)\n",
    "outputs = layers.Softmax()(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs, name=\"converea\")\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1918feab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1257/1257 [==============================] - 111s 84ms/step - loss: 9.4120 - accuracy: 0.3560\n",
      "Epoch 2/2\n",
      "1257/1257 [==============================] - 104s 82ms/step - loss: 1.3346 - accuracy: 0.3584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/converea\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/converea\\assets\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_generator, batch_size=16, epochs=2)\n",
    "tf.saved_model.save(model, './model/converea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba7c2c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./model/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42061364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 4), dtype=float32, numpy=\n",
       "array([[0.15329042, 0.34141153, 0.32754564, 0.17775244],\n",
       "       [0.15329042, 0.34141153, 0.32754564, 0.17775244],\n",
       "       [0.15329042, 0.34141153, 0.32754564, 0.17775244],\n",
       "       [0.15329042, 0.34141153, 0.32754564, 0.17775244],\n",
       "       [0.15329042, 0.34141153, 0.32754564, 0.17775244],\n",
       "       [0.15329042, 0.34141153, 0.32754564, 0.17775244],\n",
       "       [0.15329042, 0.34141153, 0.32754564, 0.17775244],\n",
       "       [0.15329042, 0.34141153, 0.32754564, 0.17775244],\n",
       "       [0.15329042, 0.34141153, 0.32754564, 0.17775244],\n",
       "       [0.15329042, 0.34141153, 0.32754564, 0.17775244],\n",
       "       [0.15329042, 0.34141153, 0.32754564, 0.17775244],\n",
       "       [0.15329042, 0.34141153, 0.32754564, 0.17775244],\n",
       "       [0.15329042, 0.34141153, 0.32754564, 0.17775244],\n",
       "       [0.15329042, 0.34141153, 0.32754564, 0.17775244],\n",
       "       [0.15329042, 0.34141153, 0.32754564, 0.17775244],\n",
       "       [0.15329042, 0.34141153, 0.32754564, 0.17775244]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = tf.saved_model.load('./model/converea')\n",
    "\n",
    "loaded(data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae95af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a3911a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dfdf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator, batch_size=16, epochs=2, use_multiprocessing=True,\n",
    "                         workers=6)\n",
    "tf.saved_model.save(model, './model/converea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c6fb67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b16c8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca5480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "os.environ['TF_CONFIG'] = json.dumps({\n",
    "    'cluster': {\n",
    "        'worker': [\"localhost:12345\", \"localhost:23456\"]\n",
    "    },\n",
    "    'task': {'type': 'worker', 'index': 0}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c40cfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1815cf48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6f5112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bf54ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SBAUser\\AppData\\Local\\Temp\\ipykernel_18004\\349189047.py:1: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "use distribute.MultiWorkerMirroredStrategy instead\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5ee633",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = 4\n",
    "# `tf.data.Dataset.batch`에는 전역 배치 크기를 지정해야 하기 때문에\n",
    "# 여기서 배치 크기는 워커의 수를 곱한 크기로 늘려야 합니다. \n",
    "# 전에는 64였지만, 이제 128이 됩니다.\n",
    "GLOBAL_BATCH_SIZE = 64 * NUM_WORKERS\n",
    "train_datasets = train_generator.batch(GLOBAL_BATCH_SIZE)\n",
    "with strategy.scope():\n",
    "    multi_worker_model = build_and_compile_cnn_model()\n",
    "multi_worker_model.fit(x=train_datasets, epochs=2)\n",
    "\n",
    "# model.fit(train_generator, batch_size=16, epochs=2)\n",
    "tf.saved_model.save(multi_worker_model, './model/converea1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d89e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25f5db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
